{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2018 Esref Ozdemir\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test Set Construction\n",
    "In this document, we construct training and test sets from already computed feature sets. The sets are computed according to the following directory layout:\n",
    "\n",
    "```\n",
    "data\n",
    "├── test\n",
    "├── test_events\n",
    "├── test_feature\n",
    "├── test_hasball\n",
    "├── train\n",
    "├── train_events\n",
    "├── train_feature\n",
    "└── train_hasball\n",
    "```\n",
    "\n",
    "When ```dataset='test'```, events are read from test_events, features are read from test_feature, hasball data is read from test_hasball and the resulting test dataset is written to test. Same logic applies to ```dataset='train'```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "from collections import Counter\n",
    "from random import shuffle\n",
    "\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from utils import plot_hbar_nameval, plot_confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "pd.set_option('compute.use_bottleneck', True)\n",
    "pd.set_option('compute.use_numexpr', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Event IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_names = {\n",
    "       0 : 'Null',\n",
    "      60 : 'Corner', \n",
    "      62 : 'Freekick',\n",
    "      80 : 'Goal',\n",
    "      93 : 'Penalty',\n",
    "}\n",
    "\n",
    "with open('../data/event_names.pkl', 'wb') as f:\n",
    "    pickle.dump(event_names, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Null event(0)** represents all the event categories, apart from the ones we are interested in, **that occur when the game stops**. If events we want to predict are possession, corner, penalty, freekick, and goal, then other events may correspond to throw-in, out, goal-kick, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete Event List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of events: 38\n"
     ]
    }
   ],
   "source": [
    "event_names = pd.read_csv('../doc/event_definitions_en.csv')\n",
    "print('Number of events: {}'.format(len(event_names)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teamId</th>\n",
       "      <th>eventId</th>\n",
       "      <th>jersey</th>\n",
       "      <th>half</th>\n",
       "      <th>minute</th>\n",
       "      <th>second</th>\n",
       "      <th>location</th>\n",
       "      <th>bodyPart</th>\n",
       "      <th>postLocation</th>\n",
       "      <th>custom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68</td>\n",
       "      <td>20</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>62</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   teamId  eventId  jersey  half  minute  second  location  bodyPart  \\\n",
       "0      11        2      23     1       0       0        -1        -1   \n",
       "1      11        2      53     1       0       1        -1        -1   \n",
       "2      68       20      77     1       0      20         6        -1   \n",
       "3      11       21      11     1       0      20         6        -1   \n",
       "4      11       62      10     1       1      23         2        -1   \n",
       "\n",
       "   postLocation  custom  \n",
       "0            -1      -1  \n",
       "1            -1      -1  \n",
       "2            -1      -1  \n",
       "3            -1      -1  \n",
       "4            -1      -1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event ids: [ 2  4 10 11 12 20 21 30 31 32 40 41 60 62 65 66 70 71 72 80 81 90 91 92 93\n",
      " 97 98]\n",
      "Size: 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teamId</th>\n",
       "      <th>eventId</th>\n",
       "      <th>jersey</th>\n",
       "      <th>half</th>\n",
       "      <th>minute</th>\n",
       "      <th>second</th>\n",
       "      <th>location</th>\n",
       "      <th>bodyPart</th>\n",
       "      <th>postLocation</th>\n",
       "      <th>custom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>11</td>\n",
       "      <td>93</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>68</td>\n",
       "      <td>93</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>44</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>11</td>\n",
       "      <td>93</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>38</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>68</td>\n",
       "      <td>93</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>42</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     teamId  eventId  jersey  half  minute  second  location  bodyPart  \\\n",
       "478      11       93      20     1      30      30        -1        -1   \n",
       "479      68       93       3     1      30      44        -1        -1   \n",
       "491      11       93       5     1      31      38        -1        -1   \n",
       "492      68       93      83     1      31      42        -1        -1   \n",
       "\n",
       "     postLocation  custom  \n",
       "478            -1       1  \n",
       "479            -1       0  \n",
       "491            -1       2  \n",
       "492            -1       3  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_df = pd.read_csv('../data/train_events/20165_event.csv')\n",
    "display(event_df.head())\n",
    "event_ids = np.sort(event_df['eventId'].unique())\n",
    "print('Event ids: {}'.format(event_ids))\n",
    "print('Size: {}'.format(len(event_ids)))\n",
    "\n",
    "event_df[event_df['eventId'] == 93]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Construction\n",
    "In this section, we construct a combined dataset containing event ids, coming from event data, and corresponding feature data, coming from feature data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "\n",
    "#### Intervals\n",
    "When obtaining feature data for a given event, we get all the feature rows in a predefined time interval for that particular event type. The main rationale behind this is that events we try to predict spread over time.\n",
    "\n",
    "* $+$: More efficient data usage.\n",
    "* $-$: In the end, time intervals are yet another hyperparameter that needs to be optimized in order to obtain an optimal model.\n",
    "* $-$: Arbitrary initial values may be totally different than reality.\n",
    "* $-$: Too large intervals would lead to **greater label noise**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the dataset to construct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "event_intervals = {\n",
    "    60 : ( 2,  0),  # corner\n",
    "    61 : ( 1,  2),  # out\n",
    "    62 : ( 2,  0),  # freekick\n",
    "    63 : ( 2,  1),  # indirect freekick\n",
    "    64 : ( 1,  0),  # throw-in\n",
    "    65 : ( 2,  0),  # offside\n",
    "    80 : ( 0, 15),  # goal\n",
    "    93 : ( 0, 15), # penalty\n",
    "    98 : ( 0,  2),  # injury\n",
    "}\n",
    "predict_event_ids = {60, 62, 80, 93}\n",
    "other_event_ids = {61, 64, 65, 98}\n",
    "# ratio of event_count/other_count\n",
    "EVENT_TO_OTHER_RATIO = 8\n",
    "# ratio of (other_count + event_count)/possession_count\n",
    "EVENT_TO_POSSESSION_RATIO = 8\n",
    "\n",
    "# file based constants\n",
    "event_dir     = '../data/{}_events'.format(dataset)\n",
    "event_regex   = re.compile(r'\\d+_event.csv')\n",
    "feature_dir   = '../data/{}_feature'.format(dataset)\n",
    "hasball_dir   = '../data/{}_hasball'.format(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions\n",
    "Generic utility functions used throughout the construction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import hms_to_sec, hms_to_sec_vec, separate_home_away\n",
    "\n",
    "\n",
    "def get_event_seconds(feature_df, hasball_df, hms, span):\n",
    "    \"\"\"\n",
    "    Returns all frames from feature_df within time limits\n",
    "    [hms - span[0], hms + span[1]] at which the game is stopped.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    feature_df: `pandas.DataFrame` containing the feature data.\n",
    "    hasball_df: `pandas.DataFrame` containing the hasball data.\n",
    "    hms: (half, minute, second) triple indicating when the event happened.\n",
    "    span: (past_limit, future_limit) pair.\n",
    "    \"\"\"\n",
    "    sec = hms_to_sec(hms)\n",
    "    begin_sec = sec - span[0]\n",
    "    end_sec   = sec + span[1]  \n",
    "    hms_vec = hms_to_sec_vec(feature_df[['half', 'minute', 'second']].values)\n",
    "    \n",
    "    sec_mask = (hms_vec >= begin_sec) & (hms_vec <= end_sec)\n",
    "    result_df = feature_df[sec_mask]\n",
    "    for index, row in result_df.iterrows():\n",
    "        hasball_row = hasball_df[(hasball_df['half'] == row['half']) & (hasball_df['minute'] == row['minute']) & (hasball_df['second'] == row['second'])]\n",
    "        if hasball_row.empty or hasball_row.at[hasball_row.index[0], 'teamPoss'] != -1:\n",
    "            result_df = result_df.drop(index)\n",
    "    #gamestop_mask = hasball_df['teamPoss'] == -1\n",
    "    \n",
    "    return result_df#[sec_mask & gamestop_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construction Related Functions\n",
    "These are functions that are heavily coupled with the construction code, and are mainly intended for local code reuse and code readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_event_features(all_events_df, events,\n",
    "                           feature_df, hasball_df, max_samples=None):\n",
    "    \"\"\"  \n",
    "    Collects features for the given events for the duration\n",
    "    specified in event_intervals. Puts collected events to\n",
    "    all_events_df and corresponding second values to event_seconds.\n",
    "    \n",
    "    If max_samples is specified, then collection stops as soon as\n",
    "    the number of collected samples is greater than max_samples.\n",
    "    \"\"\"\n",
    "    num_samples = 0\n",
    "    for eid, event_df in events.items():\n",
    "        span = event_intervals[eid]\n",
    "        for _, row in event_df.iterrows():\n",
    "            \n",
    "            # get all the features from the time interval                \n",
    "            features = get_event_seconds(\n",
    "                feature_df,\n",
    "                hasball_df,\n",
    "                row[['half', 'minute', 'second']],\n",
    "                span\n",
    "            )\n",
    "            num_samples += len(features)\n",
    "            features.insert(0, 'eventId', row['eventId'])\n",
    "            \n",
    "            # accumulate data\n",
    "            all_events_df = all_events_df.append(\n",
    "                features.drop(['half', 'minute', 'second'], axis=1),\n",
    "                ignore_index=True\n",
    "            )\n",
    "        \n",
    "            if max_samples is not None and num_samples >= max_samples:\n",
    "                return num_samples, all_events_df\n",
    "    return num_samples, all_events_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construction\n",
    "Here we construct the combined dataset from all match data we have in the given data directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct(event_file):\n",
    "    pd.options.mode.chained_assignment = None\n",
    "    all_events_df = pd.DataFrame()\n",
    "   \n",
    "    # get event data\n",
    "    event_df = pd.read_csv(join(event_dir, event_file))\n",
    "\n",
    "    # get corresponding feature data\n",
    "    match_id = event_file.split('_')[0]\n",
    "    feature_file = match_id + '_feature.csv'\n",
    "    try:\n",
    "        with open(join(feature_dir, feature_file), 'r') as f:\n",
    "            feature_df = pd.read_csv(f)\n",
    "            feature_df = feature_df.drop(0).reset_index(drop=True)\n",
    "    except FileNotFoundError:\n",
    "        print('No feature data for {}'.format(match_id))\n",
    "        return\n",
    "    \n",
    "    # get corresponding hasball data\n",
    "    hasball_file = match_id + '_hasball.csv'\n",
    "    try:\n",
    "        hasball_df = pd.read_csv(join(hasball_dir, hasball_file))\n",
    "    except FileNotFoundError:\n",
    "        print('No hasball data for {}'.format(match_id))\n",
    "        return\n",
    "\n",
    "    # get events we are interested in\n",
    "    predict_events = {eid: event_df[event_df['eventId'] == eid]\n",
    "                      for eid in predict_event_ids}\n",
    "\n",
    "    # special treatment for events that need it\n",
    "    ## start collecting goal frames 3 seconds after the event\n",
    "    predict_events[80].loc[:, 'second'] = predict_events[80]['second'] + 5\n",
    "    predict_events[93].loc[:, 'second'] = predict_events[93]['second'] + 10\n",
    "    ## use multiple custom events for penalty to get as many frames as possible\n",
    "    custom_mask = (predict_events[80]['custom'] == 0)\n",
    "    predict_events[80] = predict_events[80][custom_mask]\n",
    "    custom_mask = (predict_events[93]['custom'] == 0) | (predict_events[93]['custom'] == 1)\n",
    "    predict_events[93] = predict_events[93][custom_mask]\n",
    "    \n",
    "    \n",
    "    # get \"other\" events\n",
    "    other_events = {eid: event_df[event_df['eventId'] == eid]\n",
    "                    for eid in other_event_ids}\n",
    "    for eid in other_events.keys():\n",
    "        if not other_events[eid].empty:\n",
    "            other_events[eid] = other_events[eid].sample(frac=1)\n",
    "\n",
    "    # collect feature data corresponding to specified events\n",
    "    num_event_samples = 0\n",
    "    count, all_events_df = collect_event_features(\n",
    "        all_events_df,\n",
    "        predict_events,\n",
    "        feature_df,\n",
    "        hasball_df,\n",
    "    )\n",
    "    num_event_samples += count\n",
    "\n",
    "    # collect feature data corresponding to \"other\" events\n",
    "    count, all_events_df = collect_event_features(\n",
    "        all_events_df,\n",
    "        other_events,\n",
    "        feature_df,\n",
    "        hasball_df,\n",
    "        max_samples=int(num_event_samples//EVENT_TO_OTHER_RATIO)\n",
    "    )\n",
    "    num_event_samples += count\n",
    "\n",
    "    # first and second half begin and end seconds\n",
    "    home_mask = hasball_df['teamPoss'] == 1\n",
    "    away_mask = hasball_df['teamPoss'] == 0\n",
    "\n",
    "    # number of samples to collect for possession\n",
    "    num_possession_samples = int(num_event_samples//EVENT_TO_POSSESSION_RATIO)\n",
    "    num_home_samples = num_possession_samples//2\n",
    "    num_away_samples = num_possession_samples - num_home_samples\n",
    "\n",
    "    # collect possession samples for home team\n",
    "    try:\n",
    "        home_features = feature_df[home_mask].sample(frac=1)#n=num_home_samples)\n",
    "        home_features.insert(0, 'eventId', 0)\n",
    "        all_events_df = all_events_df.append(\n",
    "            home_features.drop(['half', 'minute', 'second'], axis=1),\n",
    "            ignore_index=True\n",
    "        )\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # collect possession samples for away team\n",
    "    try:\n",
    "        away_features = feature_df[away_mask].sample(frac=1)#n=num_away_samples)\n",
    "        away_features.insert(0, 'eventId', 0)\n",
    "        all_events_df = all_events_df.append(\n",
    "            away_features.drop(['half', 'minute', 'second'], axis=1),\n",
    "            ignore_index=True\n",
    "        )\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    for i, row in all_events_df.iterrows():\n",
    "        if row['eventId'] in other_event_ids:\n",
    "            all_events_df.loc[i, 'eventId'] = 0\n",
    "    \n",
    "    pd.options.mode.chained_assignment = 'warn'\n",
    "    \n",
    "    return all_events_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We speed up the computation by using all the CPU cores via multiprocessing module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eozd/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:81: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/home/eozd/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:92: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/home/eozd/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:81: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/home/eozd/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:92: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/home/eozd/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:81: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/home/eozd/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:81: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/home/eozd/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:92: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/home/eozd/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:92: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(61638, 45)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool = multiprocessing.Pool()\n",
    "event_csv_files = [f for f in listdir(event_dir) if event_regex.match(f)]\n",
    "shuffle(event_csv_files)\n",
    "print(len(event_csv_files))\n",
    "\n",
    "df = pd.concat(pool.map(construct, event_csv_files))\n",
    "df.sort_values('eventId', inplace=True)\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0.0: 60007, 60.0: 439, 62.0: 290, 80.0: 712, 93.0: 190})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(df.values[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eventId</th>\n",
       "      <th>awayAvgX</th>\n",
       "      <th>awayAvgY</th>\n",
       "      <th>awayConvexCenterX</th>\n",
       "      <th>awayConvexCenterY</th>\n",
       "      <th>awayConvexClosestDistance</th>\n",
       "      <th>awayConvexFarDistance</th>\n",
       "      <th>awayConvexMaxSpeed</th>\n",
       "      <th>awayConvexMaxX</th>\n",
       "      <th>awayConvexMaxY</th>\n",
       "      <th>...</th>\n",
       "      <th>playerConvexMaxX</th>\n",
       "      <th>playerConvexMaxY</th>\n",
       "      <th>playerConvexMinX</th>\n",
       "      <th>playerConvexMinY</th>\n",
       "      <th>playerDenseClusterDensity</th>\n",
       "      <th>playerSparseClusterDensity</th>\n",
       "      <th>playerVerticalLinearity</th>\n",
       "      <th>refSpeed</th>\n",
       "      <th>refX</th>\n",
       "      <th>refY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>77.793636</td>\n",
       "      <td>31.352727</td>\n",
       "      <td>80.976000</td>\n",
       "      <td>28.052000</td>\n",
       "      <td>8.634157</td>\n",
       "      <td>28.883452</td>\n",
       "      <td>4.502085</td>\n",
       "      <td>90.46</td>\n",
       "      <td>53.27</td>\n",
       "      <td>...</td>\n",
       "      <td>90.46</td>\n",
       "      <td>57.89</td>\n",
       "      <td>50.05</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.517354</td>\n",
       "      <td>0.468609</td>\n",
       "      <td>2.532833</td>\n",
       "      <td>2.959187</td>\n",
       "      <td>78.40</td>\n",
       "      <td>38.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>63.196364</td>\n",
       "      <td>29.464545</td>\n",
       "      <td>63.275000</td>\n",
       "      <td>32.475000</td>\n",
       "      <td>14.847453</td>\n",
       "      <td>34.510567</td>\n",
       "      <td>6.067635</td>\n",
       "      <td>76.35</td>\n",
       "      <td>56.13</td>\n",
       "      <td>...</td>\n",
       "      <td>76.35</td>\n",
       "      <td>66.20</td>\n",
       "      <td>36.97</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.458820</td>\n",
       "      <td>0.348719</td>\n",
       "      <td>3.280840</td>\n",
       "      <td>3.948721</td>\n",
       "      <td>59.61</td>\n",
       "      <td>34.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>54.965000</td>\n",
       "      <td>27.724000</td>\n",
       "      <td>51.887500</td>\n",
       "      <td>31.405000</td>\n",
       "      <td>13.872879</td>\n",
       "      <td>25.026157</td>\n",
       "      <td>2.854645</td>\n",
       "      <td>65.59</td>\n",
       "      <td>45.27</td>\n",
       "      <td>...</td>\n",
       "      <td>65.59</td>\n",
       "      <td>51.40</td>\n",
       "      <td>27.59</td>\n",
       "      <td>9.66</td>\n",
       "      <td>0.698171</td>\n",
       "      <td>0.440077</td>\n",
       "      <td>3.587116</td>\n",
       "      <td>0.960260</td>\n",
       "      <td>52.38</td>\n",
       "      <td>38.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>28.190000</td>\n",
       "      <td>39.857000</td>\n",
       "      <td>28.285714</td>\n",
       "      <td>37.308571</td>\n",
       "      <td>18.798221</td>\n",
       "      <td>32.275960</td>\n",
       "      <td>5.808244</td>\n",
       "      <td>51.91</td>\n",
       "      <td>62.24</td>\n",
       "      <td>...</td>\n",
       "      <td>51.91</td>\n",
       "      <td>62.24</td>\n",
       "      <td>0.21</td>\n",
       "      <td>18.98</td>\n",
       "      <td>0.513904</td>\n",
       "      <td>0.493153</td>\n",
       "      <td>1.182147</td>\n",
       "      <td>2.147859</td>\n",
       "      <td>23.42</td>\n",
       "      <td>40.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>62.302000</td>\n",
       "      <td>23.140000</td>\n",
       "      <td>63.983333</td>\n",
       "      <td>24.126667</td>\n",
       "      <td>8.855736</td>\n",
       "      <td>24.495280</td>\n",
       "      <td>1.697587</td>\n",
       "      <td>73.53</td>\n",
       "      <td>42.73</td>\n",
       "      <td>...</td>\n",
       "      <td>74.17</td>\n",
       "      <td>46.95</td>\n",
       "      <td>47.18</td>\n",
       "      <td>5.17</td>\n",
       "      <td>0.858259</td>\n",
       "      <td>0.382574</td>\n",
       "      <td>2.110818</td>\n",
       "      <td>1.889047</td>\n",
       "      <td>58.85</td>\n",
       "      <td>21.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   eventId   awayAvgX   awayAvgY  awayConvexCenterX  awayConvexCenterY  \\\n",
       "0        0  77.793636  31.352727          80.976000          28.052000   \n",
       "1        0  63.196364  29.464545          63.275000          32.475000   \n",
       "2        0  54.965000  27.724000          51.887500          31.405000   \n",
       "3        0  28.190000  39.857000          28.285714          37.308571   \n",
       "4        0  62.302000  23.140000          63.983333          24.126667   \n",
       "\n",
       "   awayConvexClosestDistance  awayConvexFarDistance  awayConvexMaxSpeed  \\\n",
       "0                   8.634157              28.883452            4.502085   \n",
       "1                  14.847453              34.510567            6.067635   \n",
       "2                  13.872879              25.026157            2.854645   \n",
       "3                  18.798221              32.275960            5.808244   \n",
       "4                   8.855736              24.495280            1.697587   \n",
       "\n",
       "   awayConvexMaxX  awayConvexMaxY  ...    playerConvexMaxX  playerConvexMaxY  \\\n",
       "0           90.46           53.27  ...               90.46             57.89   \n",
       "1           76.35           56.13  ...               76.35             66.20   \n",
       "2           65.59           45.27  ...               65.59             51.40   \n",
       "3           51.91           62.24  ...               51.91             62.24   \n",
       "4           73.53           42.73  ...               74.17             46.95   \n",
       "\n",
       "   playerConvexMinX  playerConvexMinY  playerDenseClusterDensity  \\\n",
       "0             50.05              0.77                   0.517354   \n",
       "1             36.97              0.42                   0.458820   \n",
       "2             27.59              9.66                   0.698171   \n",
       "3              0.21             18.98                   0.513904   \n",
       "4             47.18              5.17                   0.858259   \n",
       "\n",
       "   playerSparseClusterDensity  playerVerticalLinearity  refSpeed   refX   refY  \n",
       "0                    0.468609                 2.532833  2.959187  78.40  38.13  \n",
       "1                    0.348719                 3.280840  3.948721  59.61  34.85  \n",
       "2                    0.440077                 3.587116  0.960260  52.38  38.89  \n",
       "3                    0.493153                 1.182147  2.147859  23.42  40.64  \n",
       "4                    0.382574                 2.110818  1.889047  58.85  21.98  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples\t= 61638\n",
      "n_features\t= 45\n"
     ]
    }
   ],
   "source": [
    "display(df.head())\n",
    "print('n_samples\\t= {}\\nn_features\\t= {}'.format(*df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/{dataset}/all_{dataset}.csv'.format(dataset=dataset), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
