{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2018 Esref Ozdemir\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Optimization\n",
    "In this document we optimize model parameters and obtain a single, best classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "import pickle\n",
    "import datetime\n",
    "import traceback\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.linalg as la\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, KFold\n",
    "from sklearn.metrics import f1_score, make_scorer, confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from utils import plot_confusion_matrix, plot_hbar_nameval\n",
    "from utils import merge_home_away"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train/all_train.csv').dropna().reset_index(drop=True)\n",
    "X_train = train.iloc[:, 1:].values\n",
    "y_train = train['eventId'].values\n",
    "X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eventId\n",
      "awayAvgX\n",
      "awayAvgY\n",
      "awayConvexCenterX\n",
      "awayConvexCenterY\n",
      "awayConvexClosestDistance\n",
      "awayConvexFarDistance\n",
      "awayConvexMaxSpeed\n",
      "awayConvexMaxX\n",
      "awayConvexMaxY\n",
      "awayConvexMinX\n",
      "awayConvexMinY\n",
      "awayDenseClusterDensity\n",
      "awayInnerDistance\n",
      "awaySparseClusterDensity\n",
      "homeAvgX\n",
      "homeAvgY\n",
      "homeConvexCenterX\n",
      "homeConvexCenterY\n",
      "homeConvexClosestDistance\n",
      "homeConvexFarDistance\n",
      "homeConvexMaxSpeed\n",
      "homeConvexMaxX\n",
      "homeConvexMaxY\n",
      "homeConvexMinX\n",
      "homeConvexMinY\n",
      "homeDenseClusterDensity\n",
      "homeInnerDistance\n",
      "homeSparseClusterDensity\n",
      "maxClusterImpurity\n",
      "playerConvexCenterX\n",
      "playerConvexCenterY\n",
      "playerConvexClosestDistance\n",
      "playerConvexFarDistance\n",
      "playerConvexMaxSpeed\n",
      "playerConvexMaxX\n",
      "playerConvexMaxY\n",
      "playerConvexMinX\n",
      "playerConvexMinY\n",
      "playerDenseClusterDensity\n",
      "playerSparseClusterDensity\n",
      "playerVerticalLinearity\n",
      "refSpeed\n",
      "refX\n",
      "refY\n"
     ]
    }
   ],
   "source": [
    "for col in train.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 2230, 60: 2884, 62: 2345, 80: 3229, 93: 1331})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier Description\n",
    "Default classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters               : Current values\n",
      "-----------------------------------------\n",
      "bootstrap                : True\n",
      "class_weight             : None\n",
      "criterion                : gini\n",
      "max_depth                : None\n",
      "max_features             : auto\n",
      "max_leaf_nodes           : None\n",
      "min_impurity_split       : 1e-07\n",
      "min_samples_leaf         : 1\n",
      "min_samples_split        : 2\n",
      "min_weight_fraction_leaf : 0.0\n",
      "n_estimators             : 128\n",
      "n_jobs                   : -1\n",
      "oob_score                : False\n",
      "random_state             : None\n",
      "verbose                  : 0\n",
      "warm_start               : False\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(\n",
    "    n_estimators=128,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "params = clf.get_params()\n",
    "max_key_len = max(len(key) for key in params.keys())\n",
    "max_val_len = max(len(str(val)) for val in params.values())\n",
    "header = '{:<{key_width}} : {:<{val_width}}'.format(\n",
    "    'Parameters',\n",
    "    'Current values',\n",
    "    key_width=max_key_len,\n",
    "    val_width=max_val_len\n",
    ")\n",
    "\n",
    "print(header)\n",
    "print('-'*len(header))\n",
    "for key, val in params.items():\n",
    "    print('{:{width}} : {}'.format(key, val, width=max_key_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "Search space. Every possible combination will be tested by GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\n",
    "        'criterion'    : ['gini', 'entropy'],\n",
    "        'max_features' : ['sqrt', 'log2'],\n",
    "        'class_weight' : [None, 'balanced', 'balanced_subsample'],\n",
    "        'min_samples_split' : [10, 25, 35, 50],\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of combinations: 48\n"
     ]
    }
   ],
   "source": [
    "prod = 1\n",
    "for key, val in param_grid[0].items():\n",
    "    prod *= len(val)\n",
    "    \n",
    "print('Total number of combinations: {}'.format(prod))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scorer\n",
    "We implement our own scorer method that gives higher scores to classifiers that correctly classify important events (goal, corner, freekick, penalty)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 60, 62, 80, 93]\n",
      "[ 0.04761905  0.23809524  0.23809524  0.23809524  0.23809524]\n"
     ]
    }
   ],
   "source": [
    "event_labels  = sorted(list(np.unique(y_train)))\n",
    "event_weights = np.array([0.5, 2.5, 2.5, 2.5, 2.5])\n",
    "event_weights = event_weights/la.norm(event_weights, ord=1)\n",
    "print(event_labels)\n",
    "print(event_weights)\n",
    "\n",
    "\n",
    "\n",
    "def weighted_event_scorer(clf, X_test, y_test):\n",
    "    y_pred = clf.predict(X_test)\n",
    "    score_list = f1_score(y_test, y_pred, labels=event_labels, average=None)\n",
    "    \n",
    "    inner_prod = np.sum(event_weights*np.array(score_list))\n",
    "    return inner_prod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searcher\n",
    "Grid search object that does a 10-fold cross validation for each parameter configuration. Average score on a 10-fold cross validation is set as the score of that particular parameter configuration. The configuration with the highest 10-fold CV score wins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = weighted_event_scorer\n",
    "cross_validator = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "grid_search_cv = GridSearchCV(\n",
    "    estimator=clf,\n",
    "    param_grid=param_grid,\n",
    "    scoring=weighted_event_scorer,\n",
    "    n_jobs=-1,\n",
    "    cv=cross_validator,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Parameter Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 17.6min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 42.9min\n",
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed: 47.6min finished\n"
     ]
    }
   ],
   "source": [
    "# initial message accumulators\n",
    "train_result_msg = ''\n",
    "fmt = 'Training has ended in {} minutes and {} seconds'\n",
    "\n",
    "# we will measure time elapsed\n",
    "t_beg = datetime.datetime.now()\n",
    "try:\n",
    "    # train and save the grid search cross validator\n",
    "    grid_search_cv = grid_search_cv.fit(X_train, y_train)\n",
    "    with open('grid_search_cv.pkl', 'wb') as f:\n",
    "        pickle.dump(grid_search_cv, f)\n",
    "        \n",
    "    # success\n",
    "    fmt = 'SUCCESS! ' + fmt\n",
    "    fmt += '\\n\\n'\n",
    "\n",
    "    # build up success message with training results\n",
    "    result_dic = grid_search_cv.cv_results_\n",
    "    for header, content in sorted(result_dic.items()):\n",
    "        train_result_msg += '{}\\n{}\\n'.format(header, '-'*len(header))\n",
    "        train_result_msg += str(content)\n",
    "        train_result_msg += '\\n\\n\\n'\n",
    "except:\n",
    "    # send stack trace\n",
    "    fmt = 'FAILED! ' + fmt + '\\n\\n{}'.format(traceback.format_exc())\n",
    "finally:\n",
    "    # time elapsed\n",
    "    t = datetime.datetime.now() - t_beg\n",
    "    sec = t.seconds\n",
    "    minutes = sec//60\n",
    "    seconds = sec - 60*minutes\n",
    "    \n",
    "    # final message\n",
    "    msg = fmt.format(minutes, seconds) + train_result_msg\n",
    "\n",
    "# write the message to a file to be sent via email\n",
    "with open('grid_search_results.txt', 'w') as f:\n",
    "    f.write(msg + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resulting GridSearchCV\n",
    "In this section, we list the parameters of the best model picked by GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=10, random_state=None, shuffle=True),\n",
       "       error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=128, n_jobs=-1, oob_score=False,\n",
       "            random_state=None, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid=[{'criterion': ['gini', 'entropy'], 'max_features': ['sqrt', 'log2'], 'class_weight': [None, 'balanced', 'balanced_subsample'], 'min_samples_split': [10, 25, 35, 50]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=<function weighted_event_scorer at 0x7f027baaeb70>,\n",
       "       verbose=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('grid_search_cv.pkl', 'rb') as f:\n",
    "    grid_search_cv = pickle.load(f)\n",
    "    \n",
    "grid_search_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = grid_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Final Model\n",
    "In this section, we retrain the model with the optimal parameters using the whole training set and create our final model. Then, we pickle our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced_subsample',\n",
       "            criterion='gini', max_depth=None, max_features='sqrt',\n",
       "            max_leaf_nodes=None, min_impurity_split=1e-07,\n",
       "            min_samples_leaf=1, min_samples_split=10,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=128, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/random_forest.pkl', 'wb') as f:\n",
    "    f.write(pickle.dumps(clf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
